{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMc4kr3tLDuoLIeSPKZf/IP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\n","# 5Ô∏è‚É£ Load merged dataset (if already created)\n","MERGED_PATH = DATA_DIR / \"merged_dataset.csv\"\n","WEATHER_PATH = DATA_DIR / \"weather_uttarakhand.csv\" # Assuming weather data is in the same directory\n","FIRMS_PATH = DATA_DIR / \"firms_uttarakhand.csv\" # Assuming FIRMS data is in the same directory\n","\n","\n","if MERGED_PATH.exists():\n","    df = pd.read_csv(MERGED_PATH, parse_dates=[\"date\"], low_memory=False)\n","    # Recalculate dryness_idx and temp_range when loading from CSV\n","    df[\"dryness_idx\"] = df[\"temperature_2m_max\"] - 0.05 * df[\"relative_humidity_2m_mean\"]\n","    df[\"temp_range\"] = df[\"temperature_2m_max\"] - df[\"temperature_2m_min\"]\n","    print(\"‚úÖ Loaded merged dataset:\", df.shape)\n","else:\n","    # fallback: create from weather + FIRMS\n","    print(\"‚ö†Ô∏è No merged file found! Creating new one...\")\n","    firms = pd.read_csv(FIRMS_PATH, parse_dates=[\"acq_date\"])\n","    weather = pd.read_csv(WEATHER_PATH, parse_dates=[\"date\"])\n","    firms[\"acq_date\"] = pd.to_datetime(firms[\"acq_date\"]).dt.normalize()\n","    firms[\"fire_today\"] = 1\n","\n","    # Round coordinates before merging\n","    firms[\"latitude\"] = firms[\"latitude\"].round(2)\n","    firms[\"longitude\"] = firms[\"longitude\"].round(2)\n","    weather[\"lat\"] = weather[\"lat\"].round(2)\n","    weather[\"lon\"] = weather[\"lon\"].round(2)\n","\n","    df = weather.merge(firms, left_on=[\"lat\",\"lon\",\"date\"], right_on=[\"latitude\",\"longitude\",\"acq_date\"], how=\"left\")\n","    df[\"fire_today\"] = df[\"fire_today\"].fillna(0).astype(int)\n","    df = df.sort_values([\"tile_id\",\"date\"])\n","    df[\"risk_next7d\"] = df.groupby(\"tile_id\")[\"fire_today\"].shift(-7).rolling(7,min_periods=1).max().fillna(0).astype(int)\n","    df[\"dryness_idx\"] = df[\"temperature_2m_max\"] - 0.05 * df[\"relative_humidity_2m_mean\"]\n","    df[\"temp_range\"] = df[\"temperature_2m_max\"] - df[\"temperature_2m_min\"]\n","    df.to_csv(MERGED_PATH, index=False)\n","    print(\"‚úÖ Merged dataset saved:\", df.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"H3aPDTELWXX7","executionInfo":{"status":"error","timestamp":1761598225809,"user_tz":-345,"elapsed":25,"user":{"displayName":"rahul yadav","userId":"13328910521250511029"}},"outputId":"887e1d1c-54eb-49f4-8743-c65c37d297df"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚ö†Ô∏è No merged file found! Creating new one...\n"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/drive/MyDrive/forest_fire_ai/data/firms_uttarakhand.csv'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1688635939.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# fallback: create from weather + FIRMS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚ö†Ô∏è No merged file found! Creating new one...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mfirms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFIRMS_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acq_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0mweather\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWEATHER_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mfirms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acq_date\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"acq_date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/forest_fire_ai/data/firms_uttarakhand.csv'"]}]},{"cell_type":"code","source":["# Recreate dryness and temp range columns if missing\n","if 'dryness_idx' not in df.columns:\n","    df[\"dryness_idx\"] = df[\"temperature_2m_max\"] - 0.05 * df[\"relative_humidity_2m_mean\"]\n","\n","if 'temp_range' not in df.columns:\n","    df[\"temp_range\"] = df[\"temperature_2m_max\"] - df[\"temperature_2m_min\"]\n","\n","print(\"‚úÖ Added derived features: dryness_idx, temp_range\")\n","print(df[[\"dryness_idx\",\"temp_range\"]].head())\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"762WP12OcNgb","executionInfo":{"status":"ok","timestamp":1761598301521,"user_tz":-345,"elapsed":24,"user":{"displayName":"rahul yadav","userId":"13328910521250511029"}},"outputId":"ef158f7e-422d-4ea2-d98d-11f932a077cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["‚úÖ Added derived features: dryness_idx, temp_range\n","   dryness_idx  temp_range\n","0      16.9605       13.24\n","1      16.9605       13.24\n","2      16.9605       13.24\n","3      16.5575       12.73\n","4      16.5575       12.73\n"]}]},{"cell_type":"code","source":["# --- Train ML Models ---\n","features = [\n","    \"temperature_2m_mean\",\"temperature_2m_max\",\"temperature_2m_min\",\n","    \"relative_humidity_2m_mean\",\"windspeed_10m_mean\",\"precipitation_sum\",\n","    \"dryness_idx\",\"temp_range\"\n","]\n","df = df.dropna(subset=features)\n","X, y = df[features], df[\"risk_next7d\"].fillna(0).astype(int)\n","\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n","\n","Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","Xr, yr = SMOTE(random_state=42).fit_resample(Xtr, ytr)\n","\n","models = {\n","    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42, class_weight=\"balanced\"),\n","    \"GradientBoost\": GradientBoostingClassifier(n_estimators=400, learning_rate=0.05, max_depth=6)\n","}\n","\n","best_auc, best_model = 0, None\n","for name, model in models.items():\n","    print(f\"\\nüîπ Training {name}...\")\n","    model.fit(Xr, yr)\n","    prob = model.predict_proba(Xte)[:,1]\n","    pred = (prob > 0.5).astype(int)\n","    auc = roc_auc_score(yte, prob)\n","    acc = accuracy_score(yte, pred)\n","    f1  = f1_score(yte, pred)\n","    print(f\"{name}: AUC={auc:.3f} | ACC={acc:.3f} | F1={f1:.3f}\")\n","    if auc > best_auc:\n","        best_auc, best_model = auc, model\n","\n","print(\"\\n‚úÖ Best Model:\", type(best_model).__name__)\n","print(\"üî• Training Complete with High Accuracy!\")\n"],"metadata":{"id":"6G5KCSVFWcW0","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1761600465018,"user_tz":-345,"elapsed":2159089,"user":{"displayName":"rahul yadav","userId":"13328910521250511029"}},"outputId":"ece22923-e955-4bc3-d697-ef90f3697d29"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","üîπ Training RandomForest...\n","RandomForest: AUC=0.866 | ACC=0.941 | F1=0.968\n","\n","üîπ Training GradientBoost...\n","GradientBoost: AUC=0.895 | ACC=0.901 | F1=0.945\n","\n","‚úÖ Best Model: GradientBoostingClassifier\n","üî• Training Complete with High Accuracy!\n"]}]},{"cell_type":"code","source":["import joblib\n","joblib.dump(best_model, \"/content/drive/MyDrive/Colab Notebooks/data/model.pkl\")\n","print(\"‚úÖ Model saved!\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":176},"id":"UjTXH16Nb3qV","executionInfo":{"status":"error","timestamp":1761623517700,"user_tz":-345,"elapsed":33,"user":{"displayName":"rahul yadav","userId":"13328910521250511029"}},"outputId":"8a5b01da-be62-42b8-d443-fca9c3bf707f"},"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'best_model' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1681005934.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/Colab Notebooks/data/model.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"‚úÖ Model saved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from imblearn.over_sampling import SMOTE\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","from sklearn.metrics import roc_auc_score, accuracy_score, f1_score\n","\n","# --- Train ML Models ---\n","features = [\n","    \"temperature_2m_mean\",\"temperature_2m_max\",\"temperature_2m_min\",\n","    \"relative_humidity_2m_mean\",\"windspeed_10m_mean\",\"precipitation_sum\",\n","    \"dryness_idx\",\"temp_range\"\n","]\n","# Ensure df is defined, if not, load it.\n","if 'df' not in locals() or df is None:\n","    # Assuming MERGED_PATH and related variables are defined in the notebook\n","    # If not, you might need to include the data loading logic here as well\n","    try:\n","        df = pd.read_csv(MERGED_PATH, parse_dates=[\"date\"], low_memory=False)\n","        df[\"dryness_idx\"] = df[\"temperature_2m_max\"] - 0.05 * df[\"relative_humidity_2m_mean\"]\n","        df[\"temp_range\"] = df[\"temperature_2m_max\"] - df[\"temperature_2m_min\"]\n","        print(\"‚úÖ Loaded merged dataset:\", df.shape)\n","    except FileNotFoundError:\n","         print(\"Error: merged_dataset.csv not found. Please run the data loading cell first.\")\n","         # Exit or handle the error appropriately if the file is essential\n","         exit() # Exiting the cell execution if the file is not found\n","\n","\n","df = df.dropna(subset=features)\n","X, y = df[features], df[\"risk_next7d\"].fillna(0).astype(int)\n","\n","\n","Xtr, Xte, ytr, yte = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n","Xr, yr = SMOTE(random_state=42).fit_resample(Xtr, ytr)\n","\n","models = {\n","    \"RandomForest\": RandomForestClassifier(n_estimators=300, random_state=42, class_weight=\"balanced\"),\n","    \"GradientBoost\": GradientBoostingClassifier(n_estimators=400, learning_rate=0.05, max_depth=6)\n","}\n","\n","best_auc, best_model = 0, None\n","for name, model in models.items():\n","    print(f\"\\nüîπ Training {name}...\")\n","    model.fit(Xr, yr)\n","    prob = model.predict_proba(Xte)[:,1]\n","    pred = (prob > 0.5).astype(int)\n","    auc = roc_auc_score(yte, prob)\n","    acc = accuracy_score(yte, pred)\n","    f1  = f1_score(yte, pred)\n","    print(f\"{name}: AUC={auc:.3f} | ACC={acc:.3f} | F1={f1:.3f}\")\n","    if auc > best_auc:\n","        best_auc, best_model = auc, model\n","\n","print(\"\\n‚úÖ Best Model:\", type(best_model).__name__)\n","print(\"üî• Training Complete with High Accuracy!\")\n","\n","# --- Plot Feature Importance ---\n","if best_model is not None:\n","    feat_imp = pd.Series(best_model.feature_importances_, index=features).sort_values(ascending=True)\n","    feat_imp.plot(kind='barh', figsize=(8,5))\n","    plt.title('Feature Importance')\n","    plt.show()\n","else:\n","    print(\"Error: No best model was trained.\")"],"metadata":{"id":"pZn-KAV2kvA6","colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"status":"error","timestamp":1761623529049,"user_tz":-345,"elapsed":2761,"user":{"displayName":"rahul yadav","userId":"13328910521250511029"}},"outputId":"d8109970-9832-49cf-c931-e9995e15c30c"},"execution_count":3,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'MERGED_PATH' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2269589367.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;31m# If not, you might need to include the data loading logic here as well\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMERGED_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_dates\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"date\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlow_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"dryness_idx\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"temperature_2m_max\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.05\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"relative_humidity_2m_mean\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"temp_range\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"temperature_2m_max\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"temperature_2m_min\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'MERGED_PATH' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CoM51Rs68Tst"},"execution_count":null,"outputs":[]}]}